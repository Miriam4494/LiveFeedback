{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02914442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import tempfile\n",
    "import mimetypes\n",
    "import pdfplumber\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from docx import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pinecone\n",
    "import uuid\n",
    "from urllib.parse import urlparse\n",
    "from pptx import Presentation\n",
    "import zipfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "88dee27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 3\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()  # ×˜×•×¢×Ÿ ××ª ××©×ª× ×™ ×”×¡×‘×™×‘×” ××”×§×•×‘×¥ .env\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a4033cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-134' coro=<Server.serve() done, defined at C:\\Users\\user1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\uvicorn\\server.py:68> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\uvicorn\\main.py\", line 580, in run\n",
      "    server.run()\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\uvicorn\\server.py\", line 66, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py\", line 360, in __wakeup\n",
      "    self.__step()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\uvicorn\\server.py\", line 69, in serve\n",
      "    with self.capture_signals():\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\uvicorn\\server.py\", line 330, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import unquote\n",
    "import openai\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "openai.api_key = openai_api_key\n",
    "# Initialize Pinecone instance\n",
    "pinecone = Pinecone(\n",
    "    api_key=pinecone_api_key,\n",
    "    ssl_verify=False\n",
    ")\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\",\n",
    "    region=\"us-east-1\"\n",
    ")\n",
    "pinecone_index_name = \"user-files\"\n",
    "\n",
    "# ××•×“×œ ×œ×××‘×“×™× ×’\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# ×”×•×¨×“×ª ×§×•×‘×¥ ×-S3\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "def create_presigned_url(bucket_name, object_key, expiration=3600):\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=os.getenv(\"AWS_ACCES_KEY_ID\"),\n",
    "        aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCES_KEY\"),\n",
    "        )\n",
    "    try:\n",
    "        response = s3_client.generate_presigned_url('get_object',\n",
    "                                                    Params={'Bucket': bucket_name, 'Key': object_key},\n",
    "                                                    ExpiresIn=expiration)\n",
    "    except Exception as e:\n",
    "        print(f\"â— Error generating presigned URL: {e}\")\n",
    "        raise\n",
    "    return response\n",
    "\n",
    "\n",
    "def download_s3_file(s3_url):\n",
    "    print(f\"ğŸ“¥ Downloading from URL: {s3_url}\")\n",
    "    try:\n",
    "        response = requests.get(s3_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        content_type = response.headers.get('Content-Type', '')\n",
    "        extension = mimetypes.guess_extension(content_type) or ''\n",
    "        file_name = \"unknown_file\"\n",
    "\n",
    "        if not extension:\n",
    "            parsed_url = urlparse(s3_url)\n",
    "            file_name = os.path.basename(parsed_url.path)\n",
    "            extension = os.path.splitext(file_name)[1]  # ×§×‘×œ×ª ×”×¡×™×•××ª ××”×©×\n",
    "        print(f\"ğŸ“„ ×©× ×”×§×•×‘×¥ ××”-URL: {file_name}\")\n",
    "        print(f\"ğŸ“„ ×¡×™×•××ª ×”×§×•×‘×¥: {extension}\")\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=extension)\n",
    "\n",
    "        with open(temp_file.name, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"ğŸ“‚ ×§×•×‘×¥ ×–×× ×™ × ×©××¨ ×‘× ×ª×™×‘: {temp_file.name}\")\n",
    "        return temp_file.name\n",
    "    except Exception as e:\n",
    "        print(f\"â— Error downloading file: {e}\")\n",
    "        raise\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def validate_and_convert_image(file_path):\n",
    "    \"\"\"\n",
    "    ×”××¨×ª ×ª××•× ×” ×œ×¤×•×¨××˜ PNG ×× × ×“×¨×©\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(file_path)\n",
    "        converted_path = file_path + \".png\"\n",
    "        img.save(converted_path, format=\"PNG\")\n",
    "        return converted_path\n",
    "    except Exception as e:\n",
    "        print(f\"â— ×©×’×™××” ×‘×”××¨×ª ×”×ª××•× ×”: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_text(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower().replace('.', '')  # ×ª××™×“ × ×©×ª××© ×‘×¡×™×•××ª ×›××• 'txt'\n",
    "    print(f\"ğŸ“‚ × ×ª×™×‘ ×”×§×•×‘×¥: {file_path}\")\n",
    "    print(f\"ğŸ“„ ×¡×™×•××ª ×”×§×•×‘×¥: {ext}\")\n",
    "    text = \"\"\n",
    "\n",
    "    try:\n",
    "        if ext in ['txt', 'md', 'json', 'csv', 'py', 'js', 'html', 'css']:\n",
    "            # ×§×¨×™××ª ×§×‘×¦×™ ×˜×§×¡×˜\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "\n",
    "        elif ext == 'pdf':\n",
    "            # ×§×¨×™××ª ×§×‘×¦×™ PDF\n",
    "            with pdfplumber.open(file_path) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    text += page.extract_text() or \"\"\n",
    "\n",
    "        elif ext == 'docx':\n",
    "            # ×§×¨×™××ª ×§×‘×¦×™ Word\n",
    "            doc = Document(file_path)\n",
    "            for para in doc.paragraphs:\n",
    "                text += para.text + \"\\n\"\n",
    "\n",
    "        elif ext in ['jpeg', 'jpg', 'png']:\n",
    "             mime_type = f\"image/{ext if ext != 'jpg' else 'jpeg'}\"\n",
    "             text = transcribe_image_with_ai(file_path, mime_type)\n",
    "        elif ext in ['mp4', 'mov', 'avi', 'mkv']:\n",
    "            # ×ª××œ×•×œ ×•×™×“××• ×‘×××¦×¢×•×ª AI\n",
    "            text = transcribe_video_with_ai(file_path)\n",
    "        elif ext == 'zip':\n",
    "            text = extract_text_from_zip(file_path)\n",
    "        elif ext == 'pptx':\n",
    "            text = extract_text_from_pptx(file_path)\n",
    "        elif ext in ['mp3', 'wav', 'ogg']:\n",
    "            text = transcribe_audio_with_ai(file_path)\n",
    "        else:\n",
    "            print(f\"âš ï¸ ×¡×™×•××ª ×œ× × ×ª××›×ª: {ext}\")\n",
    "            text = \"×¡×•×’ ×§×•×‘×¥ ×œ× × ×ª××š ×œ×§×¨×™××” ×™×©×™×¨×”.\"\n",
    "    except Exception as e:\n",
    "        print(f\"â— ×©×’×™××” ×‘×§×¨×™××ª ×”×§×•×‘×¥: {e}\")\n",
    "        text = \"\"\n",
    "\n",
    "    return text\n",
    "\n",
    "import base64\n",
    "\n",
    "def extract_text_from_zip(file_path):\n",
    "    \"\"\"\n",
    "    ×—×™×œ×•×¥ ×˜×§×¡×˜ ××›×œ ×”×§×‘×¦×™× ×”×–××™× ×™× ×‘-ZIP (×ª×•×š ×”×ª×¢×œ××•×ª ××§×‘×¦×™× ×‘×™× ××¨×™×™×)\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            for file_info in zip_ref.infolist():\n",
    "                if not file_info.filename.endswith(('.jpg', '.png', '.mp4', '.mov', '.avi', '.mp3', '.wav')):\n",
    "                    with zip_ref.open(file_info.filename) as file:\n",
    "                        try:\n",
    "                            content = file.read().decode('utf-8', errors='ignore')\n",
    "                            text += f\"\\n\\n--- {file_info.filename} ---\\n\\n{content}\"\n",
    "                        except Exception as e:\n",
    "                            print(f\"×©×’×™××” ×‘×§×¨×™××ª {file_info.filename}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"×©×’×™××” ×‘×¤×¢× ×•×— ×§×•×‘×¥ ZIP: {e}\")\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def extract_text_from_pptx(file_path):\n",
    "    \"\"\"\n",
    "    ×©×œ×™×¤×ª ×˜×§×¡×˜ ×××¦×’×ª PowerPoint\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        prs = Presentation(file_path)\n",
    "        for slide in prs.slides:\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\"):\n",
    "                    text += shape.text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"×©×’×™××” ×‘×§×¨×™××ª PPTX: {e}\")\n",
    "    return text\n",
    "\n",
    "def transcribe_audio_with_ai(file_path):\n",
    "    \"\"\"\n",
    "    ×ª××œ×•×œ ×§×•×‘×¥ ××•×“×™×• ×‘×××¦×¢×•×ª Whisper\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as audio_file:\n",
    "            transcript = openai.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio_file\n",
    "            )\n",
    "        return transcript.text\n",
    "    except Exception as e:\n",
    "        print(f\"×©×’×™××” ×‘×ª××œ×•×œ ×”××•×“×™×•: {e}\")\n",
    "        return f\"×©×’×™××” ×‘×ª××œ×•×œ ×”××•×“×™×•: {str(e)}\"\n",
    "\n",
    "\n",
    "def transcribe_image_with_ai(file_path,mime_type):\n",
    "    \"\"\"\n",
    "    ×©×œ×™×—×ª ×ª××•× ×” ×œ-OpenAI ×¢× ×¤×¨×•××¤×˜ ××•×ª×× ×œ×§×‘×œ×ª ×ª×™××•×¨ ×©×œ ×”×ª××•× ×”\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ“¤ ×©×œ×™×—×ª ×ª××•× ×” ×œ-OpenAI ×œ×ª×™××•×¨: {file_path}\")\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as img_file:\n",
    "            b64 = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "        data_url = f\"data:{mime_type};base64,{b64}\"\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \" ×ª××¨ ×œ×™ ××ª ××” ×©×¨×•××™× ×‘×ª××•× ×” ×”×–×• ×›×•×œ×œ ××™×œ×™× ×©×¨×©×•××•×ª ×‘×”, ×¦×‘×¢×™×, ×¤×¨×˜×™× ×•×›×•'.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}},\n",
    "                ]}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"â— ×©×’×™××” ×‘×©×œ×™×—×ª ×”×ª××•× ×” ×œ-OpenAI: {e}\")\n",
    "        return f\"â— ×©×’×™××” ×‘× ×™×ª×•×— ×”×ª××•× ×” ×¢× OpenAI: {str(e)}\"\n",
    "   \n",
    "def transcribe_video_with_ai(file_path):\n",
    "    \"\"\"\n",
    "    ×ª××œ×•×œ ×•×™×“××• ×œ×§×•×‘×¥ ×˜×§×¡×˜ ×‘×¢×–×¨×ª OpenAI Whisper\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ“¤ ×©×œ×™×—×ª ×ª××•× ×” ×œ-OpenAI ×œ×ª×™××•×¨: {file_path}\")\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as video_file:\n",
    "            transcript = openai.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=video_file\n",
    "            )\n",
    "        return transcript.text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"â— ×©×’×™××” ×‘×ª××œ×•×œ ×”×•×™×“××•: {e}\")\n",
    "        return f\"â— ×©×’×™××” ×‘×ª××œ×•×œ ×”×•×™×“××•: {str(e)}\"\n",
    "\n",
    "  \n",
    "# ×¤×™×¦×•×œ ×˜×§×¡×˜ ×œ×¤×¡×§××•×ª ×§×˜× ×•×ª\n",
    "def split_text(text, max_chunk_size=500):\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for para in paragraphs:\n",
    "        if len(current_chunk) + len(para) <= max_chunk_size:\n",
    "            current_chunk += para + \"\\n\\n\"\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = para + \"\\n\\n\"\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# ×¤×•× ×§×¦×™×” ×¢×™×§×¨×™×ª: ×§×‘×œ×ª ×§×•×‘×¥, ××™× ×“×•×§×¡ ×•×©××™×¨×” ×‘-Pinecone\n",
    "def index_s3_file_for_user(s3_url: str, user_id: str,file_id: str):\n",
    "    # ×©×œ×‘ 1: ×”×•×¨×“×”\n",
    "    print(f\"ğŸ“¥ ×”×•×¨×“×ª ×”×§×•×‘×¥ ×-S3: {s3_url}\")\n",
    "    parsed_url = urlparse(s3_url)\n",
    "    bucket_name = parsed_url.netloc.split('.')[0]  \n",
    "    # object_key = parsed_url.path.lstrip('/')  \n",
    "    object_key = unquote(parsed_url.path.lstrip('/'))  # âœ… ×—×©×•×‘\n",
    "\n",
    "\n",
    "    print(\"ğŸ“‚ object_key:\", object_key)\n",
    "\n",
    "    # ×™×¦×™×¨×ª Presigned URL\n",
    "    presigned_url = create_presigned_url(bucket_name, object_key)\n",
    "\n",
    "    # ×”×•×¨×“×ª ×”×§×•×‘×¥\n",
    "    local_file_path = download_s3_file(presigned_url)    \n",
    "    # ×©×œ×‘ 2: ×§×¨×™××ª ×”×ª×•×›×Ÿ\n",
    "    text = extract_text(local_file_path)\n",
    "    if not text.strip():\n",
    "        print(f\"âš ï¸ ×”×§×•×‘×¥ ×¨×™×§ ××• ×œ× × ×ª××š: {s3_url}\")\n",
    "        os.remove(local_file_path)\n",
    "        return\n",
    "\n",
    "    # ×©×œ×‘ 3: ×—×œ×•×§×” ×œ×—×œ×§×™×\n",
    "    text_chunks = split_text(text)\n",
    "\n",
    "    # ×©×œ×‘ 4: ×™×¦×™×¨×ª ×××‘×“×™× ×’×™×\n",
    "    embeddings = embedding_model.encode(text_chunks)\n",
    "\n",
    "    # ×©×œ×‘ 5: ×©×œ×™×—×” ×œ-Pinecone\n",
    "    if pinecone_index_name not in pinecone.list_indexes().names():\n",
    "        pinecone.create_index(\n",
    "            name=pinecone_index_name,\n",
    "            dimension=len(embeddings[0]),\n",
    "            metric=\"cosine\",\n",
    "            spec=spec\n",
    "        )\n",
    "\n",
    "    index = pinecone.Index(pinecone_index_name)\n",
    "\n",
    "    vectors = []\n",
    "    for idx, (chunk, embedding) in enumerate(zip(text_chunks, embeddings)):\n",
    "        vectors.append({\n",
    "            \"id\": f\"{user_id}_{uuid.uuid4().hex}\",\n",
    "            \"values\": embedding.tolist(),\n",
    "            \"metadata\": {\n",
    "                \"user_id\": user_id,\n",
    "                \"file_id\": file_id,\n",
    "                \"text\": chunk\n",
    "            }\n",
    "        })\n",
    "\n",
    "    index.upsert(vectors)\n",
    "\n",
    "    print(f\"âœ”ï¸ {len(vectors)} ×§×˜×¢×™× ×”×•×›× ×¡×• ×œ-Pinecone ×ª×—×ª ××©×ª××© {user_id} ××”×§×•×‘×¥ {file_id}\")\n",
    "\n",
    "    # × ×™×§×•×™ ×§×•×‘×¥ ×–×× ×™\n",
    "    os.remove(local_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f0458aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_file_from_url(file_url):\n",
    "    # ×©×œ×‘ 1: ×”×•×¨×“×ª ×”×§×•×‘×¥\n",
    "    response = requests.get(file_url)\n",
    "    if response.status_code != 200:\n",
    "        return \"Failed to download the file.\"\n",
    "\n",
    "    # ×©×œ×‘ 2: ×–×™×”×•×™ ×¡×•×’ MIME\n",
    "    content_type = response.headers.get('Content-Type')\n",
    "    ext = mimetypes.guess_extension(content_type)\n",
    "\n",
    "    # ×©×œ×‘ 3: ×©××™×¨×” ×–×× ×™×ª\n",
    "    with tempfile.NamedTemporaryFile(suffix=ext, delete=False) as tmp_file:\n",
    "        tmp_file.write(response.content)\n",
    "        tmp_file_path = tmp_file.name\n",
    "\n",
    "    # ×©×œ×‘ 4: ×”×›× ×” ×œ×©×œ×™×—×” ×œ-AI\n",
    "    if 'image' in content_type:\n",
    "        # ×ª××•× ×” - ×©×œ×™×—×” ×œ-GPT-4-Vision\n",
    "        with open(tmp_file_path, \"rb\") as image_file:\n",
    "            result = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4-vision-preview\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"Please describe the content of this image.\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{content_type};base64,{image_file.read().encode('base64')}\"}}  # ×©×™××™ ×œ×‘ â€“ ×¨×§ ×× ×™×© ×ª××™×›×”\n",
    "                    ]}\n",
    "                ],\n",
    "                max_tokens=300\n",
    "            )\n",
    "            return result.choices[0].message['content']\n",
    "\n",
    "    elif 'pdf' in content_type or 'text' in content_type:\n",
    "        # ×˜×§×¡×˜×™× â€“ ×§×¨×™××” ×•×©×œ×™×—×” ×œ-GPT\n",
    "        text = response.content.decode(errors='ignore')[:2000]  # × ×™×§×— ×¨×§ ×ª×—×™×œ×ª ×”×§×•×‘×¥ ×›×“×™ ×œ× ×œ×¢×‘×•×¨ ××’×‘×œ×ª ×˜×•×§× ×™×\n",
    "        result = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Please describe the content of this file:\\n{text}\"}],\n",
    "            max_tokens=300\n",
    "        )\n",
    "        return result.choices[0].message['content']\n",
    "\n",
    "    elif 'audio' in content_type or 'video' in content_type:\n",
    "        # ×©×œ×™×—×” ×œ-Whisper (×œ×“×•×’××”, ×¨×§ ××•×“×™×•)\n",
    "        with open(tmp_file_path, \"rb\") as media_file:\n",
    "            transcript = openai.Audio.transcribe(\"whisper-1\", media_file)\n",
    "            return f\"Transcription of the file:\\n{transcript['text']}\"\n",
    "\n",
    "    else:\n",
    "        return \"Unsupported file type for automatic description.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d18d5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_user_files(user_id: str, query: str, score_threshold: float = 0.8):\n",
    "    \"\"\"\n",
    "    ×¤×•× ×§×¦×™×” ×œ×—×™×¤×•×© ×§×‘×¦×™× ×œ×¤×™ ×©××™×œ×ª×” ×•-user_id\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” ×—×™×¤×•×© ×§×‘×¦×™× ×¢×‘×•×¨ user_id: {user_id} ×¢× ×©××™×œ×ª×”: {query}\")\n",
    "    try:\n",
    "        # ×™×¦×™×¨×ª ×××‘×“×™× ×’ ×œ×©××™×œ×ª×”\n",
    "        query_embedding = embedding_model.encode([query])[0]\n",
    "\n",
    "        # ×‘×“×™×§×ª ×§×™×•× ×”××™× ×“×§×¡\n",
    "        if pinecone_index_name not in pinecone.list_indexes().names():\n",
    "            raise ValueError(f\"âš ï¸ ××™× ×“×§×¡ {pinecone_index_name} ×œ× ×§×™×™× ×‘-Pinecone.\")\n",
    "\n",
    "        # ×—×™×¤×•×© ×‘××™× ×“×§×¡\n",
    "        index = pinecone.Index(pinecone_index_name)\n",
    "        results = index.query(\n",
    "            vector=query_embedding.tolist(),\n",
    "            top_k=100,\n",
    "            include_metadata=True,\n",
    "            filter={\"user_id\": user_id}  # ×¡×™× ×•×Ÿ ×œ×¤×™ user_id\n",
    "        )\n",
    "\n",
    "        # ×¢×™×‘×•×“ ×”×ª×•×¦××•×ª\n",
    "        query_results = []\n",
    "        for match in results[\"matches\"]:\n",
    "            if match[\"score\"] >= score_threshold:  # ×¡×™× ×•×Ÿ ×œ×¤×™ ×”×¡×£\n",
    "                query_results.append({\n",
    "                    \"file_id\": match[\"metadata\"][\"file_id\"],\n",
    "                    \"text_snippet\": match[\"metadata\"][\"text\"],\n",
    "                    \"score\": match[\"score\"]\n",
    "                })\n",
    "\n",
    "        return query_results\n",
    "    except Exception as e:\n",
    "        print(f\"â— ×©×’×™××” ×‘×—×™×¤×•×© ×§×‘×¦×™×: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb9b5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import uvicorn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2db2d709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [29688]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "ERROR:    [Errno 10048] error while attempting to bind on address ('0.0.0.0', 8000): only one usage of each socket address (protocol/network address/port) is normally permitted\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# ---- ××•×“×œ×™× ×œ-Request ----\n",
    "\n",
    "class IndexFileRequest(BaseModel):\n",
    "    s3_url: str\n",
    "    user_id: int\n",
    "    file_id: int\n",
    "\n",
    "class QueryFilesRequest(BaseModel):\n",
    "    user_id: int\n",
    "    query: str\n",
    "    score_threshold: float = 0.1  # ×¡×£ ×¦×™×•×Ÿ ×‘×¨×™×¨×ª ××—×“×œ\n",
    "class QueryResult(BaseModel):\n",
    "    file_id: int\n",
    "    text_snippet: str\n",
    "    score: float\n",
    "\n",
    "# ---- ENDPOINTS ----\n",
    "\n",
    "@app.post(\"/index-file\")\n",
    "def index_file(req: IndexFileRequest):\n",
    "    try:\n",
    "        print(\"req: \",req)\n",
    "        index_s3_file_for_user(req.s3_url, req.user_id, req.file_id)\n",
    "        return {\"status\": \"success\", \"message\": \"File indexed successfully.\"}\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "@app.post(\"/query-files\", response_model=List[QueryResult])\n",
    "def query_files(req: QueryFilesRequest):\n",
    "    try:\n",
    "        results = query_user_files(req.user_id, req.query, req.score_threshold)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        return [{\"file_id\": \"\", \"text_snippet\": f\"Error: {str(e)}\", \"score\": 0.0}]\n",
    "\n",
    "# ---- ×”×¨×¦×” ----\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
